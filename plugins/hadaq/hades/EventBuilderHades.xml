<?xml version="1.0"?>

<!-- 
This is example file how HADAQ event building should be configured in DABC.
Event building process implemented in Combiner module of hadaq::CombinerModule class.
Module can have several inputs, each with separate port number for receiving data 
from TRB boards. In each input port configuration only port number has meaning.
First output of combiner module reserved for the connection to 
the optional MBS transmitter module. Second output can be use to store data in hld files. 
To enable storage, one should specify two output ports and correctly configure Output1 of combiner module.

Optionally one can enable MBS transmitter module, which converts HLD to LMD format.
To enable transmitter, one should specify auto="true" in configuration which says DABC
to automatically create module when starting application. 
First output of the module reserved for stream server, second output can be used to
store data in lmd files. 

By default, HTTP server is enabled. Do disable it, remove <HttpServer> section or
put <HttpServer name="http" auto="false">. One could change http port number. 
When dabc runs, in any browser address like
http://your_dabc_host_name:8090 can be opened. At the moment http server provides: 
  - ratemeters from EventBuilder and Transmitter
  - log fields 
  - commands to start/stop hld and lmd files from browser

It is also possible to attach go4 analysis to that server, that also histograms
from online analysis will appear. For that one should specify 
"-dabc your_dabc_host_name" argument when starting analysis. Like:
   [shell] go4analysis -stream dabc_node -dabc dabc_node
When launching analysis from the gui, extra arguments "-dabc your_dabc_host_name" 
should be specified.

There is well-known problem with using VNC viewer and mbs stream server. 
Both by default are using port 6002. One could change port number for stream server.
Just set other number in configuration of output port of transmitter module, for instance
       <OutputPort name="Output0" url="mbs://Stream:6789"/>
In this case one should specify that port number when starting go4 analysis like:
   [shell] go4analysis -stream dabc_node:6789 -dabc dabc_node:4444 
When starting analysis from the go4 gui, one should specify stream server with port number too.

Variables for hades multiple eventbuilder mode:
EBNUM   - number of event builder
STREAMS - number of input streams
UDP00...UDP34- portnumbers for input streams
PREFIX  - run prefix for filename convention (be,te,co,..)
OUTDIR - path to file output directory
RFIOPATH - path to rfio tape archive
RFIOLUSTREPATH - path to copy on lustre file system, e.g. /hera/hades/may14
RFIOCOPYMODE - 0 no copy to Lustre/hera 1 copy to Lustre after the file is in the write cash, 2 copy in parallel to Lustre
RFIOCOPYFRAC - 1 copy all

RFIOMAXFILE  - Maxfile 100,
RFIOPATHCONV - pathconvention=1 to create new subfolder on lustre after 100 events

FILEOUTPUTS - number of fileoutputs 0-none 1-local file 2-local+rfio
DAQDISK - switches disk demon mode on/off/co

-->

<dabc version="2">
  <Context host="localhost" name="DABC-EB-${EBNUM}" port="770${EBNUM}" >
    <Run>
      <lib value="libDabcMbs.so"/>
      <lib value="libDabcRfio.so"/>
      <lib value="libDabcLtsm.so"/>
      <lib value="libDabcHadaq.so"/>  
      <lib value="libDabcHttp.so"/>  
      <logfile value="EB_${EBNUM}.log"/>
      <loglevel value="1"/>
      <debuglevel value="-1"/>
      <syslog value="DAQ"/>
      <sysloglevel value="0"/>
      <loglimit value="1000000"/>
<!--       <init value=". /home/joern/dabcwork/head/dabclogin"/> -->
      <control value="true"/>
     <affinity value="-1"/>
      <!-- runtime value="30"/ -->
      <halttime value="60"/>
      <thrdstoptime value="20"/>

     <!--  <threads_layout value="maximal"/>-->
    </Run>
    
    <HttpServer name="http">
       <port value="611${EBNUM}"/>
    </HttpServer>

     <!-- shmem control config -->
    <Observer name="shm">
     <DoShmControl value="true"/>
     <NodeId value="${EBNUM}"/>     
    </Observer>  
   
      <Thread name="UdpThread*" class="dabc::SocketThread" affinity="+0"/>

    <MemoryPool name="Pool">
       <BufferSize value="200000"/>
       <NumBuffers value="3000"/>
    </MemoryPool>

    <Module name="Combiner" class="hadaq::CombinerModule">    
        <NodeId value="${EBNUM}"/>     
        <!-- these parameters will force to create inputs/oputputs of module -->        
       <NumInputs value="${STREAMS}"/>
       <NumOutputs value="${FILEOUTPUTS}"/>
       <!-- <Thread name="UdpThread*" class="dabc::SocketThread" affinity="+0"/> -->

       <InputPort name="Input0" url="hadaq://host:${UDP00}" thread="UdpThread1"/>
       <InputPort name="Input1" url="hadaq://host:${UDP01}" thread="UdpThread2"/>
       <InputPort name="Input2" url="hadaq://host:${UDP02}" thread="UdpThread3"/>
       <InputPort name="Input3" url="hadaq://host:${UDP03}" thread="UdpThread4"/>
       <InputPort name="Input4" url="hadaq://host:${UDP04}" thread="UdpThread5"/>       
       <InputPort name="Input5" url="hadaq://host:${UDP05}" thread="UdpThread1"/>
       <InputPort name="Input6" url="hadaq://host:${UDP06}" thread="UdpThread2"/>
       <InputPort name="Input7" url="hadaq://host:${UDP07}" thread="UdpThread3"/>
       <InputPort name="Input8" url="hadaq://host:${UDP08}" thread="UdpThread4"/>
       <InputPort name="Input9" url="hadaq://host:${UDP09}" thread="UdpThread5"/>       
       <InputPort name="Input10" url="hadaq://host:${UDP10}" thread="UdpThread1"/>
       <InputPort name="Input11" url="hadaq://host:${UDP11}" thread="UdpThread2"/>
       <InputPort name="Input12" url="hadaq://host:${UDP12}" thread="UdpThread3"/>
       <InputPort name="Input13" url="hadaq://host:${UDP13}" thread="UdpThread4"/>
       <InputPort name="Input14" url="hadaq://host:${UDP14}" thread="UdpThread5"/>       
       <InputPort name="Input15" url="hadaq://host:${UDP15}" thread="UdpThread1"/>
       <InputPort name="Input16" url="hadaq://host:${UDP16}" thread="UdpThread2"/>
       <InputPort name="Input17" url="hadaq://host:${UDP17}" thread="UdpThread3"/>
       <InputPort name="Input18" url="hadaq://host:${UDP18}" thread="UdpThread4"/>
       <InputPort name="Input19" url="hadaq://host:${UDP19}" thread="UdpThread5"/>
       <InputPort name="Input20" url="hadaq://host:${UDP20}" thread="UdpThread1"/>
       <InputPort name="Input21" url="hadaq://host:${UDP21}" thread="UdpThread2"/>
       <InputPort name="Input22" url="hadaq://host:${UDP22}" thread="UdpThread3"/>
       <InputPort name="Input23" url="hadaq://host:${UDP23}" thread="UdpThread4"/>
       <InputPort name="Input24" url="hadaq://host:${UDP24}" thread="UdpThread5"/>
       <InputPort name="Input25" url="hadaq://host:${UDP25}" thread="UdpThread1"/>
       <InputPort name="Input26" url="hadaq://host:${UDP26}" thread="UdpThread2"/>
       <InputPort name="Input27" url="hadaq://host:${UDP27}" thread="UdpThread3"/>
       <InputPort name="Input28" url="hadaq://host:${UDP28}" thread="UdpThread4"/>
       <InputPort name="Input29" url="hadaq://host:${UDP29}" thread="UdpThread5"/>
       <InputPort name="Input30" url="hadaq://host:${UDP30}" thread="UdpThread1"/>
       <InputPort name="Input31" url="hadaq://host:${UDP31}" thread="UdpThread2"/>
       <InputPort name="Input32" url="hadaq://host:${UDP32}" thread="UdpThread3"/>
       <InputPort name="Input33" url="hadaq://host:${UDP33}" thread="UdpThread4"/>
       <InputPort name="Input34" url="hadaq://host:${UDP34}" thread="UdpThread5"/>

       <InputPort name="Input*" queue="30" urlopt="udpbuf=400000&mtu=65507&flush=0.2&observer=true&maxloop=1"/>
       
       <!--  this is stream server for online monitoring, normally always on -->
       <OutputPort name="Output0" url="mbs://Stream:810${EBNUM}?iter=hadaq_iter&subid=0x1f"/>
              
       
       <OutputPort name="Output1" url="hld://${OUTDIR}/${PREFIX}.hld?maxsize=1000&epicsctrl&ebnumber=${EBNUM}&diskdemon=${DAQDISK}" queue="500"/>

      <!--   <OutputPort name="Output2" url="hld://${RFIOPATH}/${PREFIX}.hld?maxsize=1000&epicsctrl&ebnumber=${EBNUM}&rfio&rfioCopyMode=${RFIOCOPYMODE}&rfioCopyFrac=${RFIOCOPYFRAC}&rfioMaxFile=${RFIOMAXFILE}&rfioPathConv=${RFIOPATHCONV}&rfioLustrePath=${RFIOLUSTREPATH}" queue="500" onerror="exit" numreconn="3"/> -->

       <OutputPort name="Output2" url="hld://${LTSMPATH}/${PREFIX}.hld?maxsize=1000&epicsctrl&ebnumber=${EBNUM}&ltsm&ltsmServer=${LTSMSERVER}&ltsmNode=${LTSMNODE}&ltsmPass=${LTSMPASSWD}&ltsmFsname=${LTSMFSNAME}" queue="500" onerror="exit"/>
       <ExtraDebug value="false"/>

       <DoShmControl value="true"/>  
       <RunIdFromEPICS value="true"/>  
       <FlushTimeout value="0.5"/>
       <HadesTriggerType value="true"/>

       <!-- take event sequence number from vulom/roc sync message at cts -->
       <UseSyncSequenceNumber value="false"/>
       <SyncSubeventId value="0x8000"/>
       <SyncTriggerMask value="0x01"/>
       <PrintSync value="false"/>
       <FlushBySync value="false"/>
       <!-- TriggerNumRange: defines when trigger sequence number wraps, only 22 bit for HADES EBs!  -->
       <TriggerNumRange value="0x1000000"/>
       <!--  Do not throw away events when subevens TAGs are differ  --> 
       <CheckTag value="false"/>

       <!--AccountLostEventDiff: if true, missing trigger sequence number are added as lost events to stats. Disabled for multiple event builder mode!  -->
       <AccountLostEventDiff value="false"/>
        
       <BuildDropTimeout value="30.0"/>    
          
       <Runinfo2ora value="true"/>  
       <FilePrefix value="${PREFIX}"/> 
	  <!--        pass file prefix for runinfo2oracle here -->

       <!-- rate meters configuration -->
       <HadaqData width="4" prec="2" low="0" up="10" debug="-1"/>
       <HadaqEvents width="5" prec="1" low="0" up="1000" debug="-1"/>
       <HadaqDroppedData width="5" prec="3" low="0" up="1" debug="-1"/>
       <HadaqLostEvents width="4" prec="2" low="0" up="100" debug="-1"/>
       
     </Module>

  </Context>

  <!--Context name="*">
      <Thread name="CombinerThrdInp" class="dabc::SocketThread" affinity="+0"/>
  </Context-->
  
</dabc>
