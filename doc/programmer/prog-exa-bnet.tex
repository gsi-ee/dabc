[programmer/prog-exa-bnet.tex]
\label{prog_exabnet}
\section{Overview}

In complex experiments there are lot of front-end systems, which runs in parallel.
They takes data and marks them with trigger information or just with time stamps.
To be able analyze such data, all portions belonging to the same event (or time stamp),   
should be combined in one processing unit. Such task usually called event building.

To support event building functionality in DABC, special sub-framework called 
BNET (building network) was introduced. 
It's main aim - simplify implementation of experiment-specific event building, 
distributed over several nodes.

Typical event building network contains several \strong{readout} nodes, 
which are connected to some number of data sources each.
In readout node one reads data from data sources and combines
together data parts, which logically belongs together (so-called subevent building).
In case of trigerred system one combines together data, which has same trigger number.
In case of time-stamped data one combines together data which belongs to the same 
time interval. While one have several readout nodes, to build complete event, one
should bring together all data, which belongs to same trigger (or time interval) into
the same \strong{builder} node. 
One typically has not single but several builder nodes, therefore
full connectivity between all readouts and all builder nodes should be introduced.
Once all subevents delivered to the same builder node, one can build complete event 
and store it on the file or tape. 


BNET framework defines required functional units (modules), 
which should be used in application, 
and provides implementation of several important components.
BNET also defines topology of these functional units, which can be customized up
to definite level.


\section{Controller application}

Event building task usually distributed over several nodes, 
which should be controlled.
Therefore in BNET all nodes classified by their functionality on two kinds: controller and
workers. Workers perform all kinds of data transport and analysis codes while controller 
configures and steers all workers. 

Functionality of controller is implemented in \class{bnet::ClusterApplication} class.
Via controlling interface cluster controller distributes commands, coming from operator,
to all workers, observes status of all workers and reconfigures them automatically when 
errors are detected.

Functionality of \class{bnet::ClusterApplication} based on state-machine logic of DABC.
It means, that all actions performed during state changing command, implemented  
in virtual \func{DoStateTransition} method. State transition on cluster controller requires,
that appropriate state transition performed on all worker nodes.

Technically it means, that command, which is executed on cluster controller only than 
can be completed, when state transition commands on all workers are completed. This
is implemented with use of class \class{dabc::CommandsSet} - 
see method \func{StartClusterSMCommand} for details.  
  
Class \class{bnet::ClusterApplication} has following configuration parameters:

\begin{tabular}{llll}
\hline
Name &  Type &  Dflt & Description  \\
\hline
\param{NetDevice}           & str  & dabc::SocketDevice  &  device class for network connections \\
\param{NumEventsCombine}    & int  & 1      &  number of events (time frames) combined together  \\   
\param{TransportBuffer}     & int & 8192  &  size of buffer used for data transport cluster wide \\
\hline
\end{tabular}

Class \class{bnet::ClusterApplication} is fully functional and can be used as is in real work.
 
 
\section{Worker application}
 
Basic functionality of worker implemented in \class{bnet::WorkerApplication} class.
Its main aim - by commands from cluster controller instantiate all necessary modules, 
configure and connect them together. 

Main functionality of \class{bnet::WorkerApplication} class is implemented 
in virtual \func{CreateAppModules} method, which is called during transition 
from Halted to Configured state. In this method all local modules are instantiated 
and configured. Some of these modules should be experiment specific, therefore 
class \class{bnet::WorkerApplication} provide number of virtual methods, where 
experiment-specific components should be created:
\bbul
\item \func{CreateCombiner}  - create module to combine several data sources and produce ready subevents 
\item \func{CreateBuilder}   - create module, which combines N subevents to complete event 
\item \func{CreateFilter}    - optional filter module to filter out events 
\item \func{CreateReadout}   - creates readout (transport) connected to data source
\item \func{CreateStorage}   - creates storage (transport) to store data on disk/tape 
\ebul

Class \class{bnet::WorkerApplication} has following parameters:

\begin{tabular}{llll}
\hline
Name &  Type &  Dflt & Description  \\
\hline
\param{IsGenerator}    & bool & false  &  use generators instead of data sources  \\   
\param{IsSender}       & bool & false  &  is sender module is created (readout functionality)  \\   
\param{IsReceiver}     & bool & false  &  is receiver module is created (event builder functionality)  \\   
\param{IsFilter}       & bool & false  &  is filter module is created (event builder should be true)  \\   
\param{NumReadouts}    & int  & 1      &  number of data inputs  \\   
\param{Inpit0Cfg}      & str  &       &  string parameter to configure input 0 - user specific \\   
\param{Inpit1Cfg}      & str  &       &  string parameter to configure input 1 and so on - user specific  \\   
\param{StoragePar}         & str  &       &  string parameter to configure storage - user specific  \\   
\param{ReadoutBuffer}      & int  & 2048  &  buffer size, used for readout  \\   
\param{ReadoutPoolSize}    & int  & 4MB  &  size of memory pool for readout  \\   
\param{TransportPoolSize}  & int  & 16MB  &  size of memory pool for data transport  \\   
\param{EventBuffer}        & int  & 32768  &  buffer size, used for event building  \\   
\param{EventPoolSize}      & int  & 4MB  &  size of memory pool for event building  \\   
\hline
\end{tabular}

To implement experiment-specific BNET application, user should first of all create 
its own application class, which inherits from \class{bnet::WorkerApplication} and
implement mentioned above virtual methods. If required, one can also add more parameters.

Class \class{bnet::WorkerApplication} has also number of parameters, which
are not seen by control system and cannot be configured via xml file:

\begin{tabular}{llll}
\hline
Name &  Type &  Dflt & Description  \\
\hline
\param{CfgNodeID}    & int &  &  node id (starts from 1 for workers)  \\   
\param{CfgNumNodes}  & int &  &  number of nodes in configuration  \\   
\param{CfgSendMask}  & str & &  string in form of "xxox" defines which nodes are sender "x" or not "o" \\   
\param{CfgRecvMask}  & str & &  string in form of "xxox" defines which nodes are sender "x" or not "o"  \\   
\param{CfgClusterMgr} & str  & & name of cluster controller node \\   
\param{CfgNetDevice}   & str  & & name of configured network device, same as cluster param \param{NetDevice} \\   
\param{CfgEventsCombine}  & int  &  & number of events combined together, same as cluster param \param{NumEventsCombine}  \\   
\param{CfgReadoutPool}    & str &  &  name of memory pool, used for readout ("ReadoutPool" or "TransportPool")  \\   
\param{CfgConnected}      & bool &  &  true when local configuration of application completed  \\   
\hline
\end{tabular}
 
These parameters are set during initialization phase.
Some of them like \param{CfgEventsCombine} should be used by modules for it's configuration.  


\section{Combiner module}

Combiner module merges together several data sources and produces 
subevents packets.
Subevent here means that data from all sources, which corresponds to the same
event (or time frame) should be placed in same \class{dabc::Buffer} object.
This buffer object should has header with unique identifier of type
\decl{bnet::EventId} - 64-bit unsigned integer. 

\begin{small}
\begin{verbatim}
  ...
  dabc::Buffer* buf = fPool->TakeBuffer(bufsize);
  buf->SetHeaderSize(sizeof(bnet::EventId));
   *((bnet::EventId*) buf()->GetHeader()) = evid++;
  ...
\end{verbatim}
\end{small}

Subevent identifier should has increasing number without gap. When
no data for specific identifier is available, empty buffer with no data and
correct header should be delivered to output.

There is \class{bnet::CombinerModule} class, which provides prototype 
of combiner module. It uses following parameters:

\begin{tabular}{llll}
\hline
Name &  Type &  Dflt & Description  \\
\hline
\param{NumReadouts}    & int  & 1   &  number of data inputs  \\   
\hline
\end{tabular}

Actually, parameter \param{NumReadouts} may not be defined in the configuration of the module itself.
While class \class{bnet::WorkerApplication} already has parameter with such name,
its value will be directly used for model configuration.     

When implementing experiment-specific combiner class, 
one should either derive it's from \class{bnet::CombinerModule} class or 
start its implementation from scratch. One can add more experiment-specific
parameters to the module. 


\section{Network topology}

Topology (connectivity) of network between workers defined by parameters 
\param{IsSender} and \param{IsReceiver} of \class{bnet::WorkerApplication} class. 
By setting these parameters one can configure role of each worker:
\bbul
\item collector of data from data source(s) and sender to event builder
\item receiever of data from collectors and builder of complete events
\item both functions at the same application  
\ebul
It is required that at least one from both parameters has true value.

Cluster controller during configuration establish connections between workers so,
that each sender module connected with all receiver modules. This guarantees, that 
each receiever can get necessary data from all data sources and perform event building.

There are two bnet classes: \class{bnet::SenderModule} and \class{bnet::ReceiverModule},
which implement functionality of sender and receiver respectively. 
These classes instantiated by
\class{bnet::WorkerApplication} and should not be modified by user.     

Subevents buffers, produced by combiner module, will be delivered 
to sender module. Based on event identifier, buffer will be 
send to specific receiver, where event with such id will be build. 
For now simple round-robin schedule is used by BNET, but in next DABC versions
one or several others data transfer schedules will be implemented.
Idea of BNET framework is that such improvments should be possible without
changing of user code.  


\section{Event builder module}

Task of receiver module is to collect all buffers with same event identifier and
deliver them at once to the event builder module.

To build experiment-specific builder module, one can derive it from
\class{bnet::BuilderModule} class or start it from scratch. 
Event builder module has one input and one output. Over input module gets
N buffers with subevents for same event identifier. Over output module should deliver
buffer with build events. 
 
When user inherits its builder module from \class{bnet::BuilderModule} class,
it is enough to implement virtual \func{DoBuildEvent} method, 
which gets as argument list from N buffers with subevents. 
Format of output buffer is completely user-defined. 
One allowed to fill several events into the same output buffer if necessary.    


\section{Filter module}

This is optional component of BNET for situation, when build events should be filtered
before they are stored. To implement such filter, 
one can derived it from \class{bnet::FilterModule} and reimplement virtual method
\func{TestBuffer}. As alternative, filterring can be implemented directly in the 
event builder module.  


\section{BNET test application}
\label{prog_exabnet_test}
This is test application, which is designed for testing different asspects of BNET
without necessity to have real data sources. Complete source code and configurations 
examples can be found in \$DABCSYS/applications/bnet-test directory.  

Example contains following classes:
\bbul
\item  \class{bnet::TestGeneratorModule}
\item  \class{bnet::TestCombinerModule}
\item  \class{bnet::TestBuilderModule}
\item  \class{bnet::TestFilterModule}
\item  \class{bnet::TestWorkerApplication}
\item  \class{bnet::TestFactory}
\ebul

There are several examples of configuration files. For instance,
configuration with 4 worker nodes with sender and receiver functionality each
showin in SetupBnet.xml example:

\begin{small}
\begin{verbatim}
<?xml version="1.0"?>
<dabc version="1">
  <Context host="lxi008" name="Controller:41">
    <Application class="bnet::Cluster">
       <NetDevice value="dabc::SocketDevice"/>
    </Application>
  </Context>
  <Context host="lxi009" name="Worker1:42"/>
  <Context host="lxi010" name="Worker2:42"/>
  <Context host="lxi011" name="Worker3:42"/>
  <Context host="lxi012" name="Worker4:42"/>
  <Defaults>
    <Context name="*">
      <Run>
        <logfile value="test${DABCNODEID}.log"/>
        <loglevel value="1"/>
        <lib value="libDabcBnet.so"/>
      </Run>
    </Context>
    <Context name="Worker*">
       <Run>
          <lib value="libBnetTest.so"/>
       </Run>
       <Application class="bnet::TestWorker">
         <IsGenerator value="true"/>
         <IsSender value="true"/>
         <IsReceiver value="true"/>
         <NumReadouts value="4"/>
      </Application>       
    </Context>
  </Defaults>
</dabc>
\end{verbatim}
\end{small}

Here one can see cluster controller apllication in the beginning, configured to
use \class{dabc::SocketDevice} for workers connections. And there are four workers
with same configurations parameters, which can be found in <Defaults> section.
In section <Context name="Worker*"> one sees, 
that \param{IsGenerator}, \param{IsSender} and \param{IsReceiver} parameters are set to true.
This defines so-called all-to-all topology, when each node can communicates with all other nodes including itself.   
Parameter \param{NumReadouts}=4 means that there are 4 inputs on each combiner resulting 
in 16 data sources over complete system.

To run this example, one should specify correct host names for all contexts and 
run example with \verba{run.sh SetupBnet.xml} command.      

Example can be used as template for developing user-specific application.
One can change functionality of combiner and builder modules and provide 
real readout instead of generator module. 


\section{BNET for MBS application}

This is ready-ro-use implementation of distributed event building for MBS.
Source code can be found in \$DABCSYS/applications/bnet-mbs. It contains following
classes:
\bbul
\item  \class{bnet::MbsCombinerModule}
\item  \class{bnet::MbsBuilderModule}
\item  \class{bnet::MbsWorkerApplication}
\item  \class{bnet::MbsFactory}
\ebul

Class \class{bnet::MbsCombinerModule} combines together  
events with the same event identifier from all inputs. 
In cluster application parameter \param{NumEventsCombine} defines how many
events should be bundled togther in one buffer. It is crutial that transport
buffer size should be big enough for such number of subevents. 
Cluster parameter \param{NumEventsCombine} during initialisation copied to each
worker parameter \param{CfgEventsCombine}, which finally used in \class{bnet::MbsCombinerModule}
during initialisation: 
   
\begin{small}
\begin{verbatim}
bnet::MbsCombinerModule::MbsCombinerModule(...  
  ...
  fCfgEventsCombine = GetCfgInt(CfgEventsCombine, 1, cmd);
  ...
\end{verbatim}
\end{small}

For the moment \class{bnet::MbsCombinerModule} skips event, 
when it is not present on local data all inputs. 

Class \class{bnet::MbsBuilderModule} builds mbs events from 
delivered by receiver module buffers. It also use parameter
\param{CfgEventsCombine} from application to be sure how many real MBS events
contained in input buffers.
  
Application class \class{bnet::MbsWorkerApplication} implements several methods to
correctly instantiate combiner and builder modules.
It also implement virtual method \func{CreateReadout}, where approprite input transport 
for combiner module should be created. In case of mbs there are three possibilities:
\bnum
\item when \param{IsGenerator}=true module \class{mbs::GeneratorModule} connected as data input 
\item when appropriate readout parameter (like \param{Input0Cfg} for first input) has filename with 
      ".lmd" in the end, specified file as data input will be used
\item value of readout parameter \param{Input0Cfg} will be used as MBS server name for
      connecting of \class{mbs::ClientTransport} to appropriate data input         
\enum
In virtual method \func{CreateStorage} output lmd file will be created, if 
parameter \param{StoragePar} value is not empty.

There is example "SetupBnetMbs.xml" file, which contains running example for 
MBS event building of with 2 readout nodes, connected with 2 generators each and 
2 event builder nodes. Configuration file can be customised via variables definition in the beginning:
\begin{small}
\begin{verbatim}
<?xml version="1.0"?>
<dabc version="1">
  <Variables>
     <node0 value="lxi008"/>
     <node1 value="lxi009"/>
     <node2 value="lxi010"/>
     <node3 value="lxi011"/>
     <node4 value="lxi012"/>
     <custport value="16015"/>
  </Variables>
  ...
</dabc>
\end{verbatim}
\end{small}

Here \keyw{node0} specifies node where cluster controller will runs, \keyw{node1} and \keyw{node3} used as readout nodes,
\keyw{node2} and \keyw{node4} as builder nodes. On all four worker nodes one mbs generator
application will be started. To run application, just type \verba{run.sh SetupBnetMbs.xml}.  
