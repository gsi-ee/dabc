[programmer/prog-plugin.tex]
\section{Introduction}
A multi purpose DAQ system like \dabc~ requires to develop user specific code and adopt
this into the general framework. A common object oriented technique to realize such
extensibility consists in the definition of base classes as interfaces for dedicated purposes.
The programmer may implement subclasses for these interfaces as \strong{Plug-Ins}
with the extended functionality that matches the data format, hardware, or other boundary conditions of the
data-taking experiment. Moreover, the  \dabc~ core itself applies such powerful plug-in mechanism to provide 
generic services in a flexible and maintainable manner.   

This chapter gives a brief description of all interface classes for the data acquisition 
processing itself. This covers the processing \strong{Modules}, the \strong{Transport} and 
\strong{Device} objects that move data between the DAQ components, 
and the \strong{Application} that is responsible for the node set-up and run control.
A \strong{Factory} pattern is used to introduce new classes to the framework and let them
be available by name at runtime.


\section{Modules}

\dabc~ provides \class{dabc::Module} class, which plays role of data processing entity in framework. 
In this class necessary components like pool handles, ports, parameters, timers are organised.
Class \class{dabc::Module} has two subclasses - \class{dabc::ModuleSync} and \class{dabc::ModuleAsync},
which provides two different paradigms of data processing: 
within explicit main loop, and via event processing, respectively.
Before we discuss these two kinds of modules, 
let's consider components which can be used with both types of the module.


\subsection{Pool handles}

Class \class{dabc::PoolHandle} should be used in any module to communicate with \class{dabc::MemoryPool}.
By creating a pool handle with method \func{CreatePoolHandle()}, 
the module declares that it 
wants to use buffers from the memory pool as specified by name. 
More than one pool handles can be used in one module. 
A pool handle can be accessed with method \func{dabc::Module::FindPool()} via name,
or with method \func{dabc::Module::Pool()} via handle number (started from 0).

If a pool of the given name does not exist, 
it will be created automatically at the 
time of the first request.   
Buffer size and the number of buffers, 
which are specified in the \func{CreatePoolHandle()} call,
play a role in this case only.


\subsection{Ports}

Class \class{dabc::Port} is the only legal way to transport buffers from/to the module.
Class \class{dabc::Module} provides following methods for working with ports:

\begin{tabular}{|l|l|ll|l|}
   \hline
kind &  Create  & Count & Access & Search \\
   \hline
input   & \func{CreateInput(name, ...)} & \func{NumInputs()} & \func{Input(unsigned)} & \func{InputNumber()} \\
output  & \func{CreateOutput(name, ...)} & \func{NumOutputs()} & \func{Output(unsigned)} & \func{OutputNumber()} \\
inp/out  & \func{CreateIOPort(name, ...)} & \func{NumIOPorts()} & \func{IOPort(unsigned)} & \func{IOPortNumber()} \\
   \hline
\end{tabular}

A port usually should be created in the module constructor.
As first argument in the creation methods a unique port name should be specified.
As second argument, the pool handle should be
specified; this defines the memory pool where necessary memory can be fetched for the transports associated with the port. The Length of input or (and) output queue 
defines how many
buffers can be kept in corresponding queue. One also can specify the size of user header,
which is expected to be transported over the port - it is important for further transport configurations.    

Any kind of port can be found by name with \func{FindPort()} method.
But this is not the fastest way to work with ports, because string search is not
very efficient. 
One better should use in code methods like \func{NumInputs()} and \func{Input(unsigned)} (for input ports),
where the port id number (i.~e.~ the sequence number of port creation) is used. 

Class \class{dabc::Port} provides methods \func{Send()} and \func{Recv()} to send or receive buffers. 
While these are non-blocking methods, one should use \func{CanSend()} and \func{CanRecv()} methods 
before one can call transfer operations.


\subsection{Parameters and configurations}

Parameters are used in module for configuration, controlling and monitoring.
More information about parameters handling see in chapter \ref{prog_setup}.


\subsection{Commands processing}

There is the possibility in \dabc~ to execute user-defined commands in a module context.
Virtual method \func{ExecuteCommand()} is called every time when a command is submitted
to the module. The command is \strong{always} executed in the module thread,
disregarding from which thread the command was submitted. 
Therefore it is not necessary to protect command execution code against
module function code by means of thread locks.

Most actions in \dabc~ are performed with help of commands. 

Here is an example how command execution can look like:
\begin{small}
\begin{verbatim}
int UserModule::ExecuteCommand(dabc::Command* cmd) 
{
   if (cmd->IsName("UserPrint")) {
      DOUT1(("Printout from UserModule"));
      return dabc::cmd_true;
   }
   return dabc::ModuleSync::ExecuteCommand(cmd);
}
\end{verbatim}
\end{small}

This is invoked somewhere in the code of another component:
\begin{small}
\begin{verbatim}
...
dabc::Module* m = dabc::mgr()->FindModule("MyModule"); 
dabc::Command* cmd = new dabc::Command("UserPrint");
m->Execute(cmd);
// again, but in short form
m->Execute("UserPrint");
...
\end{verbatim}
\end{small}
After command execution has finished, 
method \func{Execute()} returns \keyw{true} or  \keyw{false},
depending on the success. The \class{dabc::Command} object 
is deleted automatically after execution.  

In the module constructor, one can register a command 
for the control system by means of a corresponding 
\class{dabc::CommandDefinition} object. 
In this case the command and its arguments are known
remotely and can be invoked from a controls GUI:
\begin{small}
\begin{verbatim}
UserModule::UserModule(const char* name) : dabc::ModuleSync(name) 
{
   ...
   dabc::CommandDefinition* def = NewCmdDef("UserPrint");
   def->AddArgument("Level", dabc::argInt, false); // optional argument
   def->Register(true);
}
\end{verbatim}
\end{small}


\subsection{ModuleSync}
\index{Core classes !dabc::ModuleSync}
\label{plugin_module_sync}
Data processing functionality in a most intuitive way can be implemented by subclassing 
the \\ 
\class{dabc::ModuleSync} base class, which defines the interface for a 
synchronous module that is allowed to block its dedicated execution thread.  

This class provides a number of methods which will block until the expected action 
can be performed.

\begin{tabular}{ll}
Method &  Description \\
   \hline
\func{Recv()} & Receive buffer from specified input port \\
\func{Send()} & Send buffers over output port \\
\func{RecvFromAny()} & Receive buffer from any of specified port \\
\func{WaitInput()} & Waits until required number of buffers is queued in input port \\
\func{TakeBuffer()} & Get buffer of specified size from memory pool \\
\func{WaitConnect()} & Waits until port is connected \\
   \hline
\end{tabular}

In all these methods a timeout value as last argument can be specified.
Method \func{SetTmoutExcept()} defines if a \class{dabc::TimeoutException} 
exception is thrown when the timeout is expired. 
By default, these blocking methods just return \keyw{false} in case of timeout.

Data processing should be implemented in \func{MainLoop()} method.
It usually contains a \strong{while()} loop where \func{ModuleWorking()} method
is used to check if execution of module code shall be continued.
This method will also execute the queued commands, if
{\em synchronous command execution} was specified before 
by method \func{SetSyncCommands()}.
By default, a command can be executed in any place of the code. 

Let's consider a simple example of a  module 
which has one input and two output ports, and delivers buffers from input to
one or another output sequentially. Implementation of such 
class will look like:
\begin{small}
\begin{verbatim}
#include "dabc/ModuleSync.h"

class RepeaterSync : public dabc::ModuleSync {
public:
   RepeaterSync(const char* name) : dabc::ModuleSync(name)
   {
      CreatePoolHandle("Pool", 2048, 1);
      CreateInput("Input", Pool(), 5);
      CreateOutput("Output0", Pool(), 5);
      CreateOutput("Output1", Pool(), 5);
   }
     
   virtual void MainLoop()
   {
      unsigned cnt(0);
      while (ModuleWorking()) {
         dabc::Buffer* buf = Recv(Input());
         if (cnt++ % 2 == 0) Send(Output(0), buf);
                        else Send(Output(1), buf);
   }
};
\end{verbatim}
\end{small}

In constructor one sees creation of pool handle and input and output ports.
Method \func{MainLoop()} has a simple {\tt while()} loop, 
that receives a buffer from the
input and then sends it alternatingly to the first or the second output.

  
\subsection{ModuleAsync}
\index{Core classes !dabc::ModuleAsync}
\label{plugin_module_async}

In contrast to data processing in \class{dabc::ModuleSync} main loop,
class \class{dabc::ModuleAsync} provides 
number of callbacks routines which are executed only if dedicated \dabc~ events occurs.
For instance, when any input port gets new buffer, virtual method \func{ProcessInputEvent} will
be called. User should reimplement this method to react on the event.

Main advantage of such approach that thread is not blocked and
several modules \class{dabc::ModuleAsync} can run within same working thread.
At the same time, using such programming technique may requires additional 
bookkeeping while it is not allowed to block callback routine, waiting that
some resource is available.

Class \class{dabc::ModuleSync} provides number of methods for handling different events:

\begin{tabular}{ll}
Method &  Description \\
   \hline
\func{ProcessInputEvent()} & new buffer in input queue, it can be read with port->Recv() \\
\func{ProcessOutputEvent()} & new place in output queue is availible, one can use port->Send()  \\
\func{ProcessConnectEvent()} & port is connected to transport  \\
\func{ProcessDisconnectEvent()} & port was disconnected from transport  \\
\func{ProcessPoolEvent()} & requested buffer can be read with handle->TakeRequestedBuffer()  \\
\func{ProcessTimerEvent()} & time has fired and event  \\
\end{tabular}

By reimplementing one or several from these methods, one can react on correspondent events.

Actually, all events are dispatched to the mentioned above metyhods by method 
\func{ProcessUserEvent()}. 
The method called by the working thread
whenever {\bf any} event for this module shall be processed.
However, this virtual method  
may also directly be re-implemented in the user subclass
if one wants to treat all events centrally. 
As arguments one get component pointer (port, timer, ...) and number of
event type (dabc::evntInput, dabc::evntOutput, ...) 
 
Class \class{dabc::ModuleAsync} has no methods, which can block thread.
Nevertheless user should avoid any kind of polling loops, waiting for some
other resource (buffer, output queue and so on) - callbacks should \strong{return}
as soon as possible. In such situation processing can be continued in 
the other callback, called when required resource is available. 
This might require an own bookkeeping of such situations (kind of state transition logic). 

Lets consider as an example same repeater module, but implemented with asynchronous module.
   
\begin{small}
\begin{verbatim}
#include "dabc/ModuleAsync.h"
#include "dabc/Port.h"

class RepeaterAsync : public dabc::ModuleAsync {
   unsigned   fCnt;
public:
   RepeaterAsync(const char* name) : dabc::ModuleAsync(name)
   {
      CreatePoolHandle("Pool", 2048, 1);
      CreateInput("Input", Pool(), 5);
      CreateOutput("Output0", Pool(), 5);
      CreateOutput("Output1", Pool(), 5);
      fCnt = 0;
   }
    
   virtual void ProcessInputEvent(dabc::Port* port) 
   {
      while (Input()->CanRecv() && Output(fCnt % 2)->CanSend()) {
         dabc::Buffer* buf = Input()->Recv();
         Output(fCnt++ % 2)->Send(buf);
      }
   }

   virtual void ProcessOutputEvent(dabc::Port* port) 
   {
      while (Input()->CanRecv() && Output(fCnt % 2)->CanSend()) {
         dabc::Buffer* buf = Input()->Recv();
         Output(fCnt++ % 2)->Send(buf);
      }
   }
};
\end{verbatim}
\end{small}

Constructor of this module has absolutely the same components as in previous example.
One should add \member{fCnt} member to count direction for output of next buffer.
Value of \member{fCnt} in some sense defines current state of the module. 
 Instaed of main loop one can see two virtual methods for input and output event
processing. In each methods one sees same code, with while loop inside.
In the loop one checks that input and current output are ready and retransmit buffer.
When any port (input or output) has no more possibility to transmit data, 
method will be returned. 

One need \keyw{while} loop here while not every input event and not every output events
leads to buffer transports. In case, when input queue is empty (\func{CanRecv} returns false) 
or output queue is full (\func{CanSend} returns false) one cannot transfer buffer from input
to output, therefore callback must be returned. But next time event processing routine is
called, one should tranfer several buffers at once. While methods \func{Send} and \func{Recv}  
cannot block, such \keyw{while} loop will not block too. But in any case one should 
avoid such \strong{wrong} code:

\begin{small}
\begin{verbatim}
   virtual void ProcessInputEvent(dabc::Port* port) 
   {
      // this kind of waiting is WRONG!!!
      while(!Output(fCnt % 2)->CanSend()) usleep(10);
   
      dabc::Buffer* buf = Input()->Recv();
      Output(fCnt++ % 2)->Send(buf);
   }

\end{verbatim}
\end{small}

Here \keyw{while} loop can wait infinite time until output port will accept new buffer
and during this time complete thread will be blocked. 

While both processing methods are the same in the example,  
one can implement central \func{ProcessUserEvent} method instead:  
 
\begin{small}
\begin{verbatim}
   virtual void ProcessUserEvent(dabc::ModuleItem*, uint16_t)
   {
      while (Input()->CanRecv() && Output(fCnt % 2)->CanSend()) {
         dabc::Buffer* buf = Input()->Recv();
         Output(fCnt++ % 2)->Send(buf);
      }
   }
\end{verbatim}
\end{small}

To introduce time-dependent activity in \class{dabc::ModuleAsync}, 
one should use timers. Timer object can be created with method 
\func{CreateTimer}. It delivers timer event with specified intervals, 
which can be processed in \func{ProcessTimerEvent()} method.

One can modify previos example to display number of transported buffers
every 5 seconds.

\begin{small}
\begin{verbatim}
   RepeaterAsync(const char* name) : dabc::ModuleAsync(name)
   {
      ...
      CreateTimer("Timer1", 5.);
   }

   virtual void ProcessUserEvent(dabc::ModuleItem* item, uint16_t evnt)
   {
      ...
      if (evnt == dabc::evntTimeout) DOUT1(("Buffers count = %d", fCnt));  
   }
\end{verbatim}
\end{small}
   

\subsection{Special modules}
For special set ups (e.g. Bnet), the framework provides 
   \class{dabc::Module} subclasses with generic functionality 
   (e.g. \class{bnet::BuilderModule}, \class{bnet::FilterModule}). 
   In this case, the user specific parts like data formats are 
   implemented by subclassing these special module classes.

   
\begin{compactenum}

\item  Instead of implementing \func{MainLoop()}, other virtual 
      methods (e.g. \func{DoBuildEvent()}, \func{TestBuffer()}) may be 
      implemented that are implicitly called by the superclass \func{MainLoop()}.
\item  The special base classes may provide additional 
      methods to be used for data processing.    
\end{compactenum}

\section{Device and transport}
\label{prog_plugin_device}
All data transport functionality is implemented by 
   subclassing  \class{dabc::Device} and \class{dabc::Transport} base classes.

\subsection{Transport}

Actual transport of buffers from/to the port is done by \class{dabc::Transport} class.
During connection time each module port gets pointer on transport object, which provides
number of methods for buffers transfer. Typically transport object runs in other thread than module itself, 
therefore transmission of the buffer happens not immediately after call of 
\func{dabc::Port::Send()} or \func{dabc::Port::Recv()} methods.

 

\subsection{Device}

Class \class{dabc::Device} is typically (but not always) represents some physical
device (like network or PCIe card) and play role of management unit for transports,
which are logically belong to that device. Device is always owner of transport object.

Device typically created in user application by:
\begin{small}
\begin{verbatim}
...
dabc::mgr()->CreateDevice("roc::Device", "ROC");
...
\end{verbatim}     
\end{small}

Later one can find device with \func{dabc::Manager::FindDevice()} method.

Device should implement method \func{CreateTranport()}, 
where appropriate transport for specified port created.
 

\subsection{Local transport}

For connection between two local ports \class{dabc::LocalTransport} is used.
It organizes queue, which shared between connected ports and pefromes
movement of \class{dabc::Buffer} pointer to/from this queue.
If correspondent modules runs in the same thread, 
local transport works without any mutexes locking.

To manage local transports, manager always has instance of \class{dabc::LocalDevice} class.
It can be always found via \func{dabc::mgr()->FindLocalDevice()} call. 
To connect two local ports, one should call:
\begin{small}
\begin{verbatim}
...
dabc::mgr()->ConnectPorts("Module1/Output", "Module2/Input");
...
\end{verbatim}     
\end{small}


\subsection{Network transport}

This is kind of transport, which is used to connect ports, situated on different nodes.
There is abstract \class{dabc::NetworkTransport} class, which introduces such kind of 
functionality. This tranport locally connected only to one port and all data
sends/receives via network connections to/from remote node. 

For the moment \dabc~ has two implementations of network transports: 
for socket and InfiniBand verbs.
To use network transport on the nodes, one should follow two step strategy. 
On first step on all nodes necessary devices and modules should be created:
\begin{small}
\begin{verbatim}
...
dabc::mgr()->CreateDevice(dabc::typeSocketDevice, "UserDev");
dabc::mgr()->CreateModule("UserModule", "MyModule");
...
\end{verbatim}     
\end{small}

Than during second step on master node 
(where \keyw{dabc::mgr()->IsMainManager()} is true)  
one should call:
\begin{small}
\begin{verbatim}
...
dabc::mgr()->ConnectPorts("Node0$MyModule/Input", "Node1$MyModule/Output", "UserDev");
...
\end{verbatim}     
\end{small}
 
Such call starts complicated sequence, when first server socket will be started by device "UserDev" on node "Node0",
than device "UserDev" on "Node1" will try to connect that server socket and than on both nodes appropriate
transports will be created, using negotiated sockets. 

Exactly for this kind of actions user \dabc~ state machine has 
two commands "DoConfigure" and "DoEnable". Accordingly class
\class{dabc::Application} has two methods \func{CreateAppModules()} and 
\func{ConnectAppModules()} 
(see correspondent section for more details).  


\subsection{Data transport}

In general case, to implement user-specific transport, one should subclass from
\class{dabc::Transport}. But this requires exact knowledge how threads working in \dabc~,
how one should organize input/output queues, how transport should request data from
memory pool, which initialization commands used by the framework. 
To simplify transport development and provide all basic services 
class \class{dabc::DataTransport} was developed.  

User should redefine following virtual methods for implement data input: 

\bbul
\item [\func{Read\_Size()}] : 
   Should return size of buffer, required to read next portion of data from
   user data source. For instance, in many file formats one has header before
   each portion of data. This method than should be used to read such header
   and define required buffer size. Method can also return following values:
   \bdes
   \item[\keyw{di\_EndOfStream}] - end of stream, normal close of the input
   \item[\keyw{di\_Repeat}]      - nothing to read now, call again as soon as possible
   \item[\keyw{di\_RepeatTimeout}] - nothing to read now, try again after timeout
   \item[\keyw{di\_Error}]         - error, close transport
   \edes

\item [\func{Read\_Timeout()}] :
   Defines timeout (in seconds) for operation like \func{Read\_Size()}
   
\item [\func{Read\_Start()}] : transport gets a 
   \func{Buffer* buf} to be filled in the read. Actual filling may be done
   asynchronously to the calling thread, e.~g.~ by DMA. Thus
   this function may initiate the asynchronous read here and return
   immeadeately before the read is complete. 
   For synchronous filling of the buffer, this function should do nothing.
   
   
\item [\func{Read\_Complete()}] :
   Called before the framework transfers the \func{Buffer* buf}
   to the connected port. The transport should no sooner return this function
    than the reading of this buffer (e.~g.~ by DMA) 
    is complete. In case of synchronous reading, the buffer filling is also
    initiated here. For asynchronous reading, 
    buffer filling has been initiated before
    in func{unsigned Read\_Start(Buffer* buf)} and this function just waits
    for a "buffer complete" state from the filling device.
      
\item [\func{Read\_CallBack()}] :
   this method MUST be called by transport when \func{Read\_Start()} 
   returns \func{di\_CallBack}. It is only way to "restart" event loop in the transport (Sergei, please explain more!)

\ebul

When implementing data output, user should just implement \func{WriteBuffer()} virtual method.  

In some cases user may redefine \func{ProcessPoolChanged()}, which is called when
memory pool changes its layout - new buffers were allocated or released. 
It may be required for DMA operations, where each buffer from memory pool
should be initialised once before it can be used for data transport.   




\subsection{Input/output objects}




\section{Factories}
The set up of the application specific objects is done 
   by \class{dabc::Factory} subclasses.
\begin{compactenum}

\item  The user must define a \class{dabc::Factory} subclass to add own classes to the system. 

\item  Each factory is instantiated as static singleton when 
      loading the library that defines it. 

\item  Factories are registered and kept in the global manager. 
      The access to the factories' functionality is done via methods of the
      manager that scans all known factories to produce the requested object
      class. 

\item  The framework provides several factories for predefined 
      implementations (e.~g.~ \class{bnet::SenderModule}, \class{verbs::Device})
            
      
\item The user factory may implement such methods:
\begin{compactdesc}
	\item [\func{Module* CreateModule(const char* classname, const char* modulename, Command* cmd)}] : 
	Instantiate a \class{dabc::Module} of class \func{classname}. The object
	name of the module is taken from \func{modulename} argument. Optional 
	argument \func{Command* cmd} may pass further creation parameters 
	from the application to the new module, encapsulated in a command object.
	
\item [\func{Device* CreateDevice(const char* classname, const char* devname, Command* cmd)}] : 
	Instantiate a \class{dabc::Device} of class \func{classname}. The object
	name of the device is taken from \func{devname} argument. Optional 
	argument \func{Command* cmd} may pass further creation parameters 
	from the application to the new device, encapsulated in a command object.
	
\item [\func{Application* CreateApplication(const char* classname, Command* cmd)}] : 
	Instantiate a \class{dabc::Application} of class \func{classname}.  Optional 
	argument \func{Command* cmd} may pass further creation parameters 
	from the set-up to the new application, encapsulated in a command object.

            
\end{compactdesc}      

Note that the factory  methods for \class{dabc::Transport} objects
belong to the corresponding \class{dabc::Device} implementation (see section \ref{prog_plugin_device})). 
      


\end{compactenum}

\section{The DABC Application}
\label{prog_plugin_applicaton}
The specific application controlling code is defined in 
   the \class{dabc::Application}.   
\begin{compactenum}
\item  The manager has exactly one application object. 
      The user must implement a \class{dabc::Application} subclass.
\item  On startup time, the \class{dabc::Application} is instantiated
by means of a factory method 
      \func{CreateApplication(const char* classname, dabc::Command* cmd)}.
The text argument \func{classname} specifies which
application subclass is created; this name is taken from a setup parameter, i.~e.~ it may be read from an XML setup file. The framework will search all
registered factories for the method which can fullfill to create an application
of that name. So the user must provide a \class{dabc::Factory} that defines such method for his/her application implementation.
      
\item  The application  may register parameters that 
      define the application's configuration. These parameters can be set at 
      runtime from the configuration and controls system.
     
\item  The user may implement virtual methods \func{UserConfigure()} ,  
      \func{UserEnable()}, \func{UserBeforeStart()}, 
      \func{UserAfterStop()}, \func{UserHalt()} in his/her 
      \class{dabc::Application} subclass. These methods are executed by the 
      framework state machine before or after the corresponding state 
      transitions to do additional application specific configuration, 
      run control, and clean-up actions. Note: all generic state machine 
      actions (e.g. cleanup of modules and devices, starting 
      and stopping the working processors) are already handled by 
      the framework at the right time and need not to be invoked explicitely here.

\item   For special DAQ topologies (e.g. Bnet), the framework offers 
      implementations of the \class{dabc::Application} containing the 
      generic functionality (e.~g.~ \class{bnet::WorkerApplication}, \class{bnet::ClusterApplication}). 
      In this case, the user specific parts are implemented by subclassing 
      these and implementing additional virtual methods (e.~g.~ \func{CreateReadout()}).    
\end{compactenum}






