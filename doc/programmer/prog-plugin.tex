[programmer/prog-plugin.tex]
\section{Introduction}
A multi purpose DAQ system like \dabc~ requires to develop user specific code and adopt
this into the general framework. A common object oriented technique to realize such
extensibility consists in the definition of base classes as interfaces for dedicated purposes.
The programmer may implement subclasses for these interfaces as \strong{Plug-Ins}
with the extended functionality that matches the data format, hardware, or other boundary conditions of the
data-taking experiment. Moreover, the  \dabc~ core itself applies such powerful plug-in mechanism to provide 
generic services in a flexible and maintainable manner.   

This chapter gives a brief description of all interface classes for the data acquisition 
processing itself. This covers the processing \strong{Modules}, the \strong{Transport} and 
\strong{Device} objects that move data between the DAQ components, 
and the \strong{Application} that is responsible for the node set-up and run control.
A \strong{Factory} pattern is used to introduce new classes to the framework and let them
be available by name at runtime.


\section{Modules}

\dabc~ provides \class{dabc::Module} class, which plays role of data processing entity in framework. 
In this class necessary components like pool handles, ports, parameters, timers are organised.
Class \class{dabc::Module} has two subclasses - \class{dabc::ModuleSync} and \class{dabc::ModuleAsync},
which provides two different paradigms of data processing: 
within explicit main loop, and via event processing, respectively.
Before we discuss these two kinds of modules, 
let's consider components which can be used with both types of the module.


\subsection{Pool handles}

Class \class{dabc::PoolHandle} should be used in any module to communicate with \class{dabc::MemoryPool}.
By creating a pool handle with method \func{CreatePoolHandle()}, 
the module declares that it 
wants to use buffers from the memory pool as specified by name. 
More than one pool handles can be used in one module. 
A pool handle can be accessed with method \func{dabc::Module::FindPool()} via name,
or with method \func{dabc::Module::Pool()} via handle number (started from 0).

If a pool of the given name does not exist, 
it will be created automatically at the 
time of the first request.   
Buffer size and the number of buffers, 
which are specified in the \func{CreatePoolHandle()} call,
play a role in this case only.


\subsection{Ports}

Class \class{dabc::Port} is the only legal way to transport buffers from/to the module.
Class \class{dabc::Module} provides following methods for working with ports:

\begin{tabular}{|l|l|ll|l|}
   \hline
kind &  Create  & Count & Access & Search \\
   \hline
input   & \func{CreateInput(name, ...)} & \func{NumInputs()} & \func{Input(unsigned)} & \func{InputNumber()} \\
output  & \func{CreateOutput(name, ...)} & \func{NumOutputs()} & \func{Output(unsigned)} & \func{OutputNumber()} \\
inp/out  & \func{CreateIOPort(name, ...)} & \func{NumIOPorts()} & \func{IOPort(unsigned)} & \func{IOPortNumber()} \\
   \hline
\end{tabular}

A port usually should be created in the module constructor.
As first argument in the creation methods a unique port name should be specified.
As second argument, the pool handle should be
specified; this defines the memory pool where necessary memory can be fetched for the transports associated with the port. The Length of input or (and) output queue 
defines how many
buffers can be kept in corresponding queue. One also can specify the size of user header,
which is expected to be transported over the port - it is important for further transport configurations.    

Any kind of port can be found by name with \func{FindPort()} method.
But this is not the fastest way to work with ports, because string search is not
very efficient. 
One better should use in code methods like \func{NumInputs()} and \func{Input(unsigned)} (for input ports),
where the port id number (i.~e.~ the sequence number of port creation) is used. 

Class \class{dabc::Port} provides methods \func{Send()} and \func{Recv()} to send or receive buffers. 
While these are non-blocking methods, one should use \func{CanSend()} and \func{CanRecv()} methods 
before one can call transfer operations.


\subsection{Parameters and configurations}

Parameters are used in module for configuration, controlling and monitoring.
More information about parameters handling see in chapter \ref{prog_setup}.


\subsection{Commands processing}

There is the possibility in \dabc~ to execute user-defined commands in a module context.
Virtual method \func{ExecuteCommand()} is called every time when a command is submitted
to the module. The command is \strong{always} executed in the module thread,
disregarding from which thread the command was submitted. 
Therefore it is not necessary to protect command execution code against
module function code by means of thread locks.

Most actions in \dabc~ are performed with help of commands. 

Here is an example how command execution can look like:
\begin{small}
\begin{verbatim}
int UserModule::ExecuteCommand(dabc::Command* cmd) 
{
   if (cmd->IsName("UserPrint")) {
      DOUT1(("Printout from UserModule"));
      return dabc::cmd_true;
   }
   return dabc::ModuleSync::ExecuteCommand(cmd);
}
\end{verbatim}
\end{small}

This is invoked somewhere in the code of another component:
\begin{small}
\begin{verbatim}
...
dabc::Module* m = dabc::mgr()->FindModule("MyModule"); 
dabc::Command* cmd = new dabc::Command("UserPrint");
m->Execute(cmd);
// again, but in short form
m->Execute("UserPrint");
...
\end{verbatim}
\end{small}
After command execution has finished, 
method \func{Execute()} returns \keyw{true} or  \keyw{false},
depending on the success. The \class{dabc::Command} object 
is deleted automatically after execution.  

In the module constructor, one can register a command 
for the control system by means of a corresponding 
\class{dabc::CommandDefinition} object. 
In this case the command and its arguments are known
remotely and can be invoked from a controls GUI:
\begin{small}
\begin{verbatim}
UserModule::UserModule(const char* name) : dabc::ModuleSync(name) 
{
   ...
   dabc::CommandDefinition* def = NewCmdDef("UserPrint");
   def->AddArgument("Level", dabc::argInt, false); // optional argument
   def->Register(true);
}
\end{verbatim}
\end{small}


\subsection{ModuleSync}
\index{Core classes !dabc::ModuleSync}
\label{plugin_module_sync}
Data processing functionality in a most intuitive way can be implemented by subclassing 
the \\ 
\class{dabc::ModuleSync} base class, which defines the interface for a 
synchronous module that is allowed to block its dedicated execution thread.  

This class provides a number of methods which will block until the expected action 
can be performed.

\begin{tabular}{ll}
Method &  Description \\
   \hline
\func{Recv()} & Receive buffer from specified input port \\
\func{Send()} & Send buffers over output port \\
\func{RecvFromAny()} & Receive buffer from any of specified port \\
\func{WaitInput()} & Waits until required number of buffers is queued in input port \\
\func{TakeBuffer()} & Get buffer of specified size from memory pool \\
\func{WaitConnect()} & Waits until port is connected \\
   \hline
\end{tabular}

In all these methods a timeout value as last argument can be specified.
Method \func{SetTmoutExcept()} defines if a \class{dabc::TimeoutException} 
exception is thrown when the timeout is expired. 
By default, these blocking methods just return \keyw{false} in case of timeout.

Data processing should be implemented in \func{MainLoop()} method.
It usually contains a \strong{while()} loop where \func{ModuleWorking()} method
is used to check if execution of module code shall be continued.
This method will also execute the queued commands, if
{\em synchronous command execution} was specified before 
by method \func{SetSyncCommands()}.
By default, a command can be executed in any place of the code. 

Let's consider a simple example of a  module 
which has one input and two output ports, and delivers buffers from input to
one or another output sequentially. Implementation of such 
class will look like:
\begin{small}
\begin{verbatim}
#include "dabc/ModuleSync.h"

class RepeaterSync : public dabc::ModuleSync {
public:
   RepeaterSync(const char* name) : dabc::ModuleSync(name)
   {
      CreatePoolHandle("Pool", 2048, 1);
      CreateInput("Input", Pool(), 5);
      CreateOutput("Output0", Pool(), 5);
      CreateOutput("Output1", Pool(), 5);
   }
     
   virtual void MainLoop()
   {
      unsigned cnt(0);
      while (ModuleWorking()) {
         dabc::Buffer* buf = Recv(Input());
         if (cnt++ % 2 == 0) Send(Output(0), buf);
                        else Send(Output(1), buf);
   }
};
\end{verbatim}
\end{small}

In constructor one sees creation of pool handle and input and output ports.
Method \func{MainLoop()} has a simple {\tt while()} loop, 
that receives a buffer from the
input and then sends it alternatingly to the first or the second output.

  
\subsection{ModuleAsync}
\index{Core classes !dabc::ModuleAsync}
\label{plugin_module_async}

In contrast to data processing in \class{dabc::ModuleSync} main loop,
class \class{dabc::ModuleAsync} provides 
number of callbacks routines which are executed only if dedicated \dabc~ events occurs.
For instance, when any input port gets new buffer, virtual method \func{ProcessInputEvent} will
be called. User should reimplement this method to react on the event.

Main advantage of such approach that thread is not blocked and
several modules \class{dabc::ModuleAsync} can run within same working thread.
At the same time, using such programming technique may requires additional 
bookkeeping while it is not allowed to block callback routine, waiting that
some resource is available.

Class \class{dabc::ModuleSync} provides number of methods for handling different events:

\begin{tabular}{ll}
Method &  Description \\
   \hline
\func{ProcessInputEvent()} & new buffer in input queue, it can be read with port->Recv() \\
\func{ProcessOutputEvent()} & new place in output queue is availible, one can use port->Send()  \\
\func{ProcessConnectEvent()} & port is connected to transport  \\
\func{ProcessDisconnectEvent()} & port was disconnected from transport  \\
\func{ProcessPoolEvent()} & requested buffer can be read with handle->TakeRequestedBuffer()  \\
\func{ProcessTimerEvent()} & time has fired and event  \\
\end{tabular}

By reimplementing one or several from these methods, one can react on correspondent events.

Actually, all events are dispatched to the mentioned above methods by method 
\func{ProcessUserEvent()}. 
The method called by the working thread
whenever {\bf any} event for this module shall be processed.
However, this virtual method  
may also directly be re-implemented in the user subclass
if one wants to treat all events centrally. 
As arguments one get component pointer (port, timer, ...) and number of
event type (dabc::evntInput, dabc::evntOutput, ...) 
 
Class \class{dabc::ModuleAsync} has no methods, which can block thread.
Nevertheless user should avoid any kind of polling loops, waiting for some
other resource (buffer, output queue and so on) - callbacks should \strong{return}
as soon as possible. In such situation processing can be continued in 
the other callback, called when required resource is available. 
This might require an own bookkeeping of such situations (kind of state transition logic). 

Lets consider as an example same repeater module, but implemented with asynchronous module.
   
\begin{small}
\begin{verbatim}
#include "dabc/ModuleAsync.h"
#include "dabc/Port.h"

class RepeaterAsync : public dabc::ModuleAsync {
   unsigned   fCnt;
public:
   RepeaterAsync(const char* name) : dabc::ModuleAsync(name)
   {
      CreatePoolHandle("Pool", 2048, 1);
      CreateInput("Input", Pool(), 5);
      CreateOutput("Output0", Pool(), 5);
      CreateOutput("Output1", Pool(), 5);
      fCnt = 0;
   }
    
   virtual void ProcessInputEvent(dabc::Port* port) 
   {
      while (Input()->CanRecv() && Output(fCnt % 2)->CanSend()) {
         dabc::Buffer* buf = Input()->Recv();
         Output(fCnt++ % 2)->Send(buf);
      }
   }

   virtual void ProcessOutputEvent(dabc::Port* port) 
   {
      while (Input()->CanRecv() && Output(fCnt % 2)->CanSend()) {
         dabc::Buffer* buf = Input()->Recv();
         Output(fCnt++ % 2)->Send(buf);
      }
   }
};
\end{verbatim}
\end{small}

Constructor of this module has absolutely the same components as in previous example.
One should add \member{fCnt} member to count direction for output of next buffer.
Value of \member{fCnt} in some sense defines current state of the module. 
 Instaed of main loop one can see two virtual methods for input and output event
processing. In each methods one sees same code, with while loop inside.
In the loop one checks that input and current output are ready and retransmit buffer.
When any port (input or output) has no more possibility to transmit data, 
method will be returned. 

One need \keyw{while} loop here while not every input event and not every output events
leads to buffer transports. In case, when input queue is empty (\func{CanRecv} returns false) 
or output queue is full (\func{CanSend} returns false) one cannot transfer buffer from input
to output, therefore callback must be returned. But next time event processing routine is
called, one should tranfer several buffers at once. While methods \func{Send} and \func{Recv}  
cannot block, such \keyw{while} loop will not block too. But in any case one should 
avoid such \strong{wrong} code:

\begin{small}
\begin{verbatim}
   virtual void ProcessInputEvent(dabc::Port* port) 
   {
      // this kind of waiting is WRONG!!!
      while(!Output(fCnt % 2)->CanSend()) usleep(10);
   
      dabc::Buffer* buf = Input()->Recv();
      Output(fCnt++ % 2)->Send(buf);
   }

\end{verbatim}
\end{small}

Here \keyw{while} loop can wait infinite time until output port will accept new buffer
and during this time complete thread will be blocked. 

While both processing methods are the same in the example,  
one can implement central \func{ProcessUserEvent} method instead:  
 
\begin{small}
\begin{verbatim}
   virtual void ProcessUserEvent(dabc::ModuleItem*, uint16_t)
   {
      while (Input()->CanRecv() && Output(fCnt % 2)->CanSend()) {
         dabc::Buffer* buf = Input()->Recv();
         Output(fCnt++ % 2)->Send(buf);
      }
   }
\end{verbatim}
\end{small}

To introduce time-dependent activity in \class{dabc::ModuleAsync}, 
one should use timers. Timer object can be created with method 
\func{CreateTimer}. It delivers timer event with specified intervals, 
which can be processed in \func{ProcessTimerEvent()} method.

One can modify previos example to display number of transported buffers
every 5 seconds.

\begin{small}
\begin{verbatim}
   RepeaterAsync(const char* name) : dabc::ModuleAsync(name)
   {
      ...
      CreateTimer("Timer1", 5.);
   }

   virtual void ProcessUserEvent(dabc::ModuleItem* item, uint16_t evnt)
   {
      ...
      if (evnt == dabc::evntTimeout) DOUT1(("Buffers count = %d", fCnt));  
   }
\end{verbatim}
\end{small}
   

\subsection{Special modules}
For special set ups (e.g. Bnet), the framework provides 
   \class{dabc::Module} subclasses with generic functionality 
   (e.g. \class{bnet::BuilderModule}, \class{bnet::FilterModule}). 
   In this case, the user specific parts like data formats are 
   implemented by subclassing these special module classes.

   
\begin{compactenum}

\item  Instead of implementing \func{MainLoop()}, other virtual 
      methods (e.g. \func{DoBuildEvent()}, \func{TestBuffer()}) may be 
      implemented that are implicitly called by the superclass \func{MainLoop()}.
\item  The special base classes may provide additional 
      methods to be used for data processing.    
\end{compactenum}

\section{Device and transport}
\label{prog_plugin_device}
All data transport functionality is implemented by 
   subclassing  \class{dabc::Device} and \class{dabc::Transport} base classes.

\subsection{Transport}

Actual transport of buffers from/to the port is done by \class{dabc::Transport} class.
During connection time each module port gets pointer on transport object, which provides
number of methods for buffers transfer. Typically transport object runs in other thread than module itself, 
therefore transmission of the buffer happens not immediately after call of 
\func{dabc::Port::Send()} or \func{dabc::Port::Recv()} methods.

 

\subsection{Device}

Class \class{dabc::Device} is typically (but not always) represents some physical
device (like network or PCIe card) and play role of management unit for transports,
which are logically belong to that device. Device is always owner of transport object.

Device typically created in user application by:
\begin{small}
\begin{verbatim}
...
dabc::mgr()->CreateDevice("roc::Device", "ROC");
...
\end{verbatim}     
\end{small}

Later one can find device with \func{dabc::Manager::FindDevice()} method.

Device should implement method \func{CreateTranport()}, 
where appropriate transport for specified port created.
 

\subsection{Local transport}

For connection between two local ports \class{dabc::LocalTransport} is used.
It organizes queue, which shared between connected ports and performes
movement of \class{dabc::Buffer} pointer to/from this queue.
If correspondent modules runs in the same thread, 
local transport works without any mutexes locking.

To manage local transports, manager always has instance of \class{dabc::LocalDevice} class.
It can be always found via \func{dabc::mgr()->FindLocalDevice()} call. 
To connect two local ports, one should call:
\begin{small}
\begin{verbatim}
...
dabc::mgr()->ConnectPorts("Module1/Output", "Module2/Input");
...
\end{verbatim}     
\end{small}


\subsection{Network transport}

This is kind of transport, which is used to connect ports, situated on different nodes.
There is abstract \class{dabc::NetworkTransport} class, which introduces such kind of 
functionality. This tranport locally connected only to one port and all data
sends/receives via network connections to/from remote node. 

For the moment \dabc~ has two implementations of network transports: 
for socket and InfiniBand verbs.
To use network transport on the nodes, one should follow two step strategy. 
On first step on all nodes necessary devices and modules should be created:
\begin{small}
\begin{verbatim}
...
dabc::mgr()->CreateDevice(dabc::typeSocketDevice, "UserDev");
dabc::mgr()->CreateModule("UserModule", "MyModule");
...
\end{verbatim}     
\end{small}

Than during second step on master node 
(where \keyw{dabc::mgr()->IsMainManager()} is true)  
one should call:
\begin{small}
\begin{verbatim}
...
dabc::mgr()->ConnectPorts("Node0$MyModule/Input", "Node1$MyModule/Output", "UserDev");
...
\end{verbatim}     
\end{small}
 
Such call starts complicated sequence, when first server socket will be started by device "UserDev" on node "Node0",
than device "UserDev" on "Node1" will try to connect that server socket and than on both nodes appropriate
transports will be created, using negotiated sockets. 

Exactly for this kind of actions user \dabc~ state machine has 
two commands "DoConfigure" and "DoEnable". Accordingly class
\class{dabc::Application} has two methods \func{CreateAppModules()} and 
\func{ConnectAppModules()} (see \ref{prog_plugin_applicaton}).  


\subsection{Data transport}

In general case, to implement user-specific transport, one should subclass from
\class{dabc::Transport}. But this requires exact knowledge how threads working in \dabc~,
how one should organize input/output queues, how transport should request data from
memory pool, which initialization commands used by the framework. 
To simplify transport development and provide all basic services 
class \class{dabc::DataTransport} was developed.  

User should redefine following virtual methods for implement data input: 

\bbul
\item [\func{Read\_Size()}] : 
   Should return size of buffer, required to read next portion of data from
   user data source. For instance, in many file formats one has header before
   each portion of data. This method than should be used to read such header
   and define required buffer size. Method can also return following values:
   \bdes
   \item[\keyw{dabc::di\_EndOfStream}] - end of stream, normal close of the input
   \item[\keyw{dabc::di\_Repeat}]      - nothing to read now, call again as soon as possible
   \item[\keyw{dabc::di\_RepeatTimeout}] - nothing to read now, try again after timeout
   \item[\keyw{dabc::di\_Error}]         - error, close transport
   \edes

\item [\func{Read\_Timeout()}] :
   Defines timeout (in seconds) for operation like \func{Read\_Size()}
   
\item [\func{Read\_Start()}] : Starts reading of buffer. Should return:
   \bdes
   \item[\keyw{dabc::di\_Ok}]       - normal case, call of \func{Read\_Complete()} will follow
   \item[\keyw{dabc::di\_Error}]    - error, skip buffer, starts again from \func{Read\_Size()}
   \item[\keyw{dabc::di\_CallBack}] - asynchron readout, user should call \func{Read\_CallBack()}  
   \edes
   If \keyw{di\_CallBack} returned, event loop for transport is stopped until
   user calls \func{Read\_CallBack()} method, providing result of reading: 
   \keyw{di\_Ok} or \keyw{di\_Error}. This mode is only possible if device driver
   has its own thread and possibility to call \dabc~ methods. Big advantage of such modus -
   data transport thread is not blocked by waiting result from device, therefore several
   transports can share same thread. 
   
\item [\func{Read\_Complete()}] :
   Finish reading of the buffer. Can returns:  
   \bdes
   \item[\keyw{dabc::di\_Ok}]           - normal, buffer will be delivered to port
   \item[\keyw{dabc::di\_Error}]        - error, close transport
   \item[\keyw{dabc::di\_EndOfStream}]  - end of stream, normal close of the transport
   \item[\keyw{dabc::di\_SkipBuffer}]   - normal, but buffer will not be deliver to the port
   \item[\keyw{dabc::di\_Repeat}]       - not ready, call again as soon as possible
   \item[\keyw{dabc::di\_RepeatTimeout}] - not ready, call again after timeout
   \edes
   In simple case actual reading of data performed in this method.
   Or one can wait that other thread fills buffer. 
   In this case one should be carefull and not block thread forever - 
   better return with \keyw{dabc::di\_Repeat}, that thread can continue event loop and 
   handle other workers.  
\ebul

When implementing data output, user should just implement \func{WriteBuffer()} virtual method.  

In some cases user may redefine \func{ProcessPoolChanged()}, which is called when
memory pool changes its layout - new buffers were allocated or released. 
It may be required for DMA operations, where each buffer from memory pool
should be initialised once before it can be used for data transport.   

Instantiation of user written data transport should be done via factory method
\func{CreateTransport} (see \ref{prog_plugin_factory}). 
One not need to create user-specific device for data transport - 
standard local device can be used, while it only required as owner of transport object. 


\subsection{Input/output objects}

\dabc~ provides possibility to implement simple input/output objects in form
of classes, derived from \class{dabc::DataInput} and \class{dabc::DataOutput}.
These classes provides interface similiar to that \class{dabc::DataTransport} has,
but they are not dependent from any other components (threads, devices and so) 
and therefore can be used absolutely independent from \dabc~ data flow engine.
The only feature, which is not supported by \class{dabc::DataInput} - call back 
mode.

In addition, methods \func{dabc::DataInput::Read\_Init()} and
\func{dabc::DataOutput::Write\_Init()} can be implemented to get 
configuration from port object, to which i/o object may be assigned to.  

Typical use of input/output objects is file I/O. 
For instance, lmd file handling implemented
using these classes.

To instantiate such classes, user should inplement factories methods 
\func{CreateDataInput()} and \func{CreateDataOutput()} (see \ref{prog_plugin_factory}).


\section{The DABC Application}
\label{prog_plugin_applicaton}
The specific application controlling code is defined in the \class{dabc::Application}.

On startup time, the \class{dabc::Application} is instantiated
by means of a factory method \func{CreateApplication()}.
As argument, factories get application class name, provided from configuration file.
Thus, to use his/her application implementation, 
the user must provide a \class{dabc::Factory} that defines such method.

The manager has exactly one application object - name of this object always "App".
Application can always be accessed via \func{dabc::mgr()->GetApp()} call. 

The application  may register parameters that 
define the application's configuration. These parameters can be set at 
runtime from the configuration file or by controls system.

Main aim of application class - add user-specific actions during
execution of state machine commands. Application has virtual method 
\func{DoStateTransition()} which is called from SM during state change.
As argument, name of state transition command is delivered. 
There are following SM commands:

\bdes
\item[\keyw{dabc::Manager::stcmdDoConfigure}] - creates all necessary application components: devices, modules, memory pools
\item[\keyw{dabc::Manager::stcmdDoEnable}] - connect local and (or) remote nodes together (if necessary) 
\item[\keyw{dabc::Manager::stcmdDoStart}] - starts execution of user modules 
\item[\keyw{dabc::Manager::stcmdDoStop}] - stop execution of user modules
\item[\keyw{dabc::Manager::stcmdDoHalt}] - destroy all components, created during configure
\item[\keyw{dabc::Manager::stcmdDoError}] - react on error, which happened during other commands
\edes
  
Class \class{dabc::Application} already has default implementation for
\func{DoStateTransition()} method, where some virtual methods are called:

\bdes
\item[\func{CreateAppModules()}] - creates all necessary application components
\item[\func{ConnectAppModules()}] - activity to connect with remote nodes or  
\item[\func{IsAppModulesConnected()}] - check if connection is already performed  
\item[\func{BeforeAppModulesStarted()}] - optional activity before modules started 
\item[\func{AfterAppModulesStopped()}] - optional activity after modules stopped
\item[\func{BeforeAppModulesDestroyed()}] - optional call before modules destroyed
\edes

Actually, for single-node application it is enough to implement \func{CreateAppModules()},
while all other methods have meaningfull implementation for that case. 

For special DAQ topologies (e.g. Bnet), the framework offers 
implementations of the \class{dabc::Application} containing the 
generic functionality (e.~g.~ \class{bnet::WorkerApplication}, \class{bnet::ClusterApplication}). 
In this case, the user specific parts are implemented by subclassing 
and implementing additional virtual methods (e.~g.~ \func{CreateReadout()}).    



\section{Factories}
\label{prog_plugin_factory}

The creation of the application specific objects is done by \class{dabc::Factory} subclasses.

The user must define a \class{dabc::Factory} 
subclass to add own classes to the system.
Factory should be instantiated as static singleton - this will create factory  
immediately after library, containing factory, is loaded. 

Factories are registered and kept in the global manager. 
The access to the factories' functionality is done via methods of the
manager that scans all known factories to produce the requested object class. 

The \dabc~ framework provides several factories for predefined 
implementations (e.~g.~ \class{bnet::SenderModule}, \class{verbs::Device})


The user factory may implement such methods:
\bdes
	\item [\func{CreateModule()}] : 
	Instantiate a \class{dabc::Module} of specified class. 
	
\item [\func{CreateDevice()}] : 
	Instantiate a \class{dabc::Device} of specified class. 

\item [\func{CreateThread()}] : 
   Instantiate a \class{dabc::WorkingThread} of specified class.
	
\item [\func{CreateApplication()}] : 
	Instantiate a \class{dabc::Application} of specified class.

\item [\func{CreateTransport()}] : 
   Instantiate a \class{dabc::Transport} of specified class.
   This method is used when transport does not requires specific device functionality
   (like \class{dabc::DataTransport}). Typically transport objects
   created by the \class{dabc::Device} methods.   
	
\item [\func{CreateDataInput()}] : 
   Instantiate a \class{dabc::DataInput} of specified type.
   Initialisation of object will be done by \func{Read\_Init()} call.

\item [\func{CreateDataOutput()}] : 
   Instantiate a \class{dabc::DataOutput} of specified type.
   Initialisation of object will be done by \func{Write\_Init()} call.
	
\edes      

All mentioned here methods have equivalent methods in \class{dabc::Manager} class.
Manager simply iterates over all factories and execute appropriate factory method
until object is created. For instance, to create module, one should do:

\begin{small}
\begin{verbatim}
...
dabc::mgr()->CreateModule("mbs::GeneratorModule", "Generator");
...
\end{verbatim}     
\end{small}

Invocation of these methods in manager is implemented via correspondent commands
(for instance, \comm{CmdCreateModule} for module creation). 
These command classes should be used directly, if one wants to deliver extra 
configuration parameters to objects constructor (most factories methods gets
this command as optional argument). For instance:

\begin{small}
\begin{verbatim}
...
dabc::Command* cmd = new dabc::CmdCreateModule("mbs::GeneratorModule", "Generator");
cmd->SetInt("NumSubevents", 5);
cmd->SetInt("SubeventSize", 64);
dabc::mgr()->Execute(cmd);
...
\end{verbatim}     
\end{small}







